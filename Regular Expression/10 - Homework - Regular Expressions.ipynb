{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 10: Cleaning data with Regular Expressions\n",
    "\n",
    "Time to use regular expressions!\n",
    "\n",
    "# Hints and notes\n",
    "\n",
    "### Opening files in subdirectories\n",
    "\n",
    "Notice that this notebook might be **homework/**, but!!! the csvs and text files might be in **homework/scraped/** or **/homework/scraped/minutes_pdfs** or **/homework/pdfs/**. To open a file in a subdirectory, instead of having the filename be `\"file.csv\"` you'll just use `\"some/subfolder/file.csv\"`\n",
    "\n",
    "### Opening text files\n",
    "\n",
    "This will open up a file, read it in and show you the first 500 characters.\n",
    "\n",
    "```python\n",
    "contents = open(\"your-filename.txt\").read()\n",
    "contents[0:500]\n",
    "```\n",
    "\n",
    "> You might need `open(\"your-filename.txt\", encoding=\"utf8\").read()`\n",
    "\n",
    "### Using regex\n",
    "\n",
    "For some dumb reason you need to put `r` in front of the string you use when you're talking about regex. Just plain `\"(\\d\\d\\d)\"` will usually work, but *sometimes* it won't and you'll need `r\"(\\d\\d\\d)`. It's best to just use the `r` all of the time, if you can remember!\n",
    "\n",
    "### Using `.str.extract`\n",
    "\n",
    "When you use `.str.extract`, you're always going to **capture one thing** and save it to a new column. You need to wrap the things you're interested in with parenthesis `(` `)`.\n",
    "\n",
    "```python\n",
    "df['phone_number'] = df['old_column'].str.extract(r\"My phone number is (\\d\\d\\d-\\d\\d\\d-\\d\\d\\d\\d)\")\n",
    "```\n",
    "\n",
    "### Setting pandas options\n",
    "\n",
    "Pandas has a lot of options, like how many columns or rows it will show you, or how many characters it will show in a column before it stops showing you anything. Here are a few useful ones:\n",
    "\n",
    "* `display.max_cols`: Number of columns to show at once\n",
    "* `display.max_rows`: Number of rows to show at once\n",
    "* `display.max_colwidth`: Maximum number of characters displayed from a string\n",
    "\n",
    "You can set them using `pd.set_option(\"display.max_rows\", 1000)`, for example, to show 1000 rows at a time. You can find a lot more at https://pandas.pydata.org/pandas-docs/stable/generated/pandas.set_option.html\n",
    "\n",
    "### Regular expressions reference\n",
    "\n",
    "I personally think http://www.regular-expressions.info/ is a wonderful wonderful reference (and tutorial), even if it's ugly! But here's a quick reference for you:\n",
    "\n",
    "* `\\d` is a digit\n",
    "* `\\d*` is zero or more digits \n",
    "* `\\d+` is one or more digits\n",
    "* `.` matches anything for ONE character\n",
    "* `.*` is \"give me anything forever\"\n",
    "* `\\s` is whitespace, a.k.a. spaces and tabs\n",
    "* `\\w` is a word character, which includes capital and lowercase letters, numbers and hyphens.\n",
    "* You can put `*` after anything, so `\\w*` would mean \"as many word characters as you can find\"\n",
    "* `\\b` is a word boundary (you'll need the `r\"\"` thing for this one)\n",
    "* `( )` is a \"capture group\" for saving something\n",
    "* `\\1` is used when doing find/replace to say \"put the first captured group here\" (note, it's a dollar sign instead of a backslash in some editors)\n",
    "* `[ABCDE]` is a character class, which means \"match one of these, I don't care which\"\n",
    "* dollar sign means \"end of the line\"\n",
    "* caret ^ means \"beginning of the line\"\n",
    "* `\\.` means \"no really seriously I mean a period not just anything\"\n",
    "* You can use `\\` with anything else that would normally be a special character, too, not just periods. `(` or `[` or whatever.\n",
    "\n",
    "### Cleaning up extracted columns\n",
    "\n",
    "Sometimes you get `\\n` (newlines) or spaces or `\\t` (tabs) or stuff at the beginning or the end of your column. `.str.strip()` will usually take care of that, just attach it after your `.str.extract()`\n",
    "\n",
    "After you extract something, it's still a string even though you look at it and know it's a number. Use `.astype(int)` to turn it into an integer (no decimal) or `.astype(float)` to turn it into a float (yes decimal)\n",
    "\n",
    "### Writing regular expressions in general\n",
    "\n",
    "Even if I'm using regex in pandas or Python, I like to test them in my text editor with \"Find.\" The highlighting really helps me see if I'm matching things! I also like to think \"what stays the same?\" when designing patterns, write those parts first, then fill in the blanks with what I want to capture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing\n",
    "\n",
    "There might be more, I just wanted to put this up here for the `pd.set_option` part. It allows you to see a lot of content in a single column of pandas, which will be important for some parts below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Using `.str.extract` to pull data from columns in pandas\n",
    "\n",
    "## 1.1 H&M\n",
    "\n",
    "Open up `hm.csv` from the `scraped` directory. I want **four new columns**:\n",
    "\n",
    "1. `price_original`, the original price, one of the new price\n",
    "2. `price_discounted`, the discounted price\n",
    "3. `pct_discount`, the percent discount\n",
    "4. `article_id`, the article id (from the url)\n",
    "\n",
    "Save as **hm_cleaned.csv**.\n",
    "\n",
    "**Note:** When you look at it, it... won't look right. I don't know why, pandas is weird. Look at the `price` column by itself using `df['price']` before you write your regex.\n",
    "\n",
    "**Tip:** Remember that `$` is a special regex symbol! You might need to escape it.\n",
    "\n",
    "**Tip:** When doing `.str.extract`, the whole match doesn't get captured, only what you put `()` around! Think about anchoring to different points of the string, or things in the string.\n",
    "\n",
    "**Tip:** Not all prices have cents!\n",
    "\n",
    "**Tip:** Your first instinct about how to compute the percent discount is probably wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('scraped/hm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "df['price_discounted'] = df.price.str.extract(\"^[$](\\d+[.]?\\d+)\\s+\")\n",
    "df['price_original'] = df.price.str.extract(\"\\s+[$](\\d+[.]?\\d+)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    pct_discount = round((1-(df.price_discounted.astype(float))/(df.price_original.astype(float)))*100,2)\n",
    "    df['pct_discount'] = pct_discount\n",
    "#df.drop(['pct_discount'],axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['article_id'] = df.url.str.extract(\"[?]article=(\\d+[-]\\w)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.to_csv('hm_cleaned.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Sci-Fi Authors\n",
    "\n",
    "Open up `sci-fi.csv` to clean. Get rid of the `\\n` on the title and and give me six new columns:\n",
    "\n",
    "* `avg_rating`\n",
    "* `rating_count`\n",
    "* `total_score`\n",
    "* `score_votes`\n",
    "* `series` the series the book belongs to\n",
    "* `series_no` the book in the series that it is\n",
    "\n",
    "For series, I'm talking about e.g. `(The Hunger Games, #1)` is `series` \"The Hunter Games\" and `series_no` 1.\n",
    "\n",
    "Save as **sci-fi_cleaned.csv**.\n",
    "\n",
    "**Tip:** You don't need regex to clean the title - there's a special thing that removes whitespace from the beginning/end of strings\n",
    "\n",
    "**Tip:** Remember that `(` and `)` are special characters\n",
    "\n",
    "**BONUS:** When you make the `total_score` column, pay close attention to it. If you notice the problem, fix it.\n",
    "\n",
    "**BONUS:** You don't need these columns to be numbers, but life would be better if they were. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"scraped/sci-fi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.title = df.title.str.strip()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_rating\n",
    "df['avg_rating'] = df.full_rating.str.extract(r\"\\s(\\d[.]\\d+)\\savg\").astype(float)\n",
    "df['rating_count'] = df.full_rating.str.extract(r\"[â€”]\\s(\\d+[,]?\\d*[,]?\\d*)\\sratings\")\n",
    "\n",
    "\n",
    "# series the series the book belongs to\n",
    "# series_no the book in the series that it is\n",
    "df['total_score'] = df.full_score.str.extract(r\"score:\\s(\\d+[,]\\d+)\")\n",
    "df['score_votes'] = df.full_score.str.extract(r\"(\\d+)\\speople\")\n",
    "\n",
    "#I didn't use the comma to end this regex because i found one series without a comma...\n",
    "df['series'] = df.title.str.extract(r\"[(](.*)[#]\")\n",
    "\n",
    "df['series_no'] = df.title.str.extract(r\"#(\\d+)[)]\").astype(float)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('sci-fi_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Where you're just doing one of my former students' projects\n",
    "\n",
    "Once upon a time my student Stefan did a project that involved some lawyer stuff. Most of the content was in PDFs, though! I converted them to text files and put them into the `pdfs` folder, and gave you code below to open up each of them and save their contents into a dataframe.\n",
    "\n",
    "What a nice dataframe! I want you to add the following columns to it:\n",
    "\n",
    "* `lawyer_app`, the applicant's lawyer (pro se means that they did it themselves, that's fine)\n",
    "* `lawyer_gov`, the government's lawyer\n",
    "* `judge`, the name of the judge\n",
    "* `access`, whether the clearance is granted or denied (although you might miss a few)\n",
    "\n",
    "Save as **court_cleaned.csv**.\n",
    "\n",
    "**Note:** You can look at the original PDFs, they're also included.\n",
    "\n",
    "**Note:** This uses a fun utility called `glob`, which is mostly fun because you use it as `glob.glob`. It's used to find files that match a certain filename pattern.\n",
    "\n",
    "**BONUS:** You'll be happy once you get the judge, but make sure it doesn't have any extra punctuation on it.\n",
    "\n",
    "**BONUS:** You can for some words using `.str.contains(\"blah\")` and save it into new columns. Maybe `has_debt`, `has_bankruptcy`, etc.\n",
    "\n",
    "> It's okay if it isn't perfect. Converting PDF into data rarely is! Usually you get 90% of it done with computers, then send people to enter the other 10% by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "filenames = glob.glob(\"pdfs/*.txt\")\n",
    "contents = [open(filename, encoding=\"utf8\").read() for filename in filenames]\n",
    "df = pd.DataFrame({'filename': filenames, 'content': contents})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('courts.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('courts.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Okay, now do the work and **make those new columns!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['lawyer_app'] = df.content.str.extract(r\"F\\w+ A\\w+[:\\n]+?(.*\\w)[.]?\\s\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lawyer_gov'] = df.content.str.extract(r\"F\\w+ G\\w+[:\\n]+?(.*\\w)[,]\\s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['judge'] = df.content.str.extract(r\"(.*), Administrative Judge[:]\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_access(row):\n",
    "    if re.findall(\"classified information is granted.\",row['content']):\n",
    "        return \"granted\"\n",
    "    elif re.findall(\"classified information is denied.\" , row['content']) or re.findall(\"declined to grant\",row['content']):\n",
    "        return \"denied\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['access'] = df.apply(get_access, axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('court_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading books\n",
    "\n",
    "When you're doing text work, you're legally obligated work on Jane Austen's Pride and Prejudice (at least I *think* so). Let's do some naive analysis of it!\n",
    "\n",
    "## Read in Jane Austen's Pride and Prejudice (without moving the file!)\n",
    "\n",
    "It's in the `data/` directory, and named `Austen_Pride.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = open(\"data/Austen_Pride.txt\", encoding=\"utf8\").read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the first 500 or so characters of it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a regular expression to find every \"he\" or \"she\" in the book. There should be about 3000 of them.\n",
    "\n",
    "**Tip:** Do you know about **word boundaries?** `\\b` means \"the beginning of end of a word.\"\n",
    "\n",
    "**Tip:** You might also want to use `re.IGNORECASE`. Maybe you'll need to google it? \n",
    "\n",
    "**Tip:** Do NOT use `re.compile`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "he_she = re.findall(r\"\\bs?he\\b\", contents, re.IGNORECASE)\n",
    "he_she[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a regular expression to find those same \"he\" or \"she\"s, but also match *the word after it*\n",
    "\n",
    "The first four should be:\n",
    "\n",
    "* he is\n",
    "* he had\n",
    "* she told\n",
    "* he came"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_she_word = re.findall(r\"\\bs?he\\b \\w+\",contents, re.IGNORECASE)\n",
    "he_she_word[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use capture groups to save the pronoun (he/she) as one match and the word as another\n",
    "\n",
    "The first five should look like\n",
    "\n",
    "```\n",
    "[('he', 'is'),\n",
    " ('he', 'had'),\n",
    " ('she', 'told'),\n",
    " ('he', 'came'),\n",
    " ('he', 'agreed')]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_she_word_group = re.findall(r\"(\\bs?he\\b) (\\w+)\",contents, re.IGNORECASE)\n",
    "he_she_word_group[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save those matches into a dataframe\n",
    "\n",
    "You can give the column names with `columns=['pronoun', 'verb']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(he_she_word_group, columns = ['pronoun', 'verb'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many times is each pronoun used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "she    1647\n",
       "he     1288\n",
       "Name: pronoun, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(df['pronoun'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oh, wait, clean that up.\n",
    "\n",
    "Make it only 'he' and 'she' lowercase.\n",
    "\n",
    "It should be about 1600 'she' and 1300 'he'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pronoun.replace('He', \"he\", inplace=True)\n",
    "df.pronoun.replace('She','she',inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the top 20 most common verbs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.verb.value_counts(sort = True).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the top 20 most common verbs for 'he', and the top 20 most common for 'she'\n",
    "\n",
    "**Tip:** Don't use groupby, just filter. If you want to know how, though, you can also look at \"value counts for different categories\" on [this page](http://jonathansoma.com/lede/foundations-2017/classes/more-pandas/class-notes/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"pronoun\")['verb'].value_counts().groupby(level=0).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Who cries more, men or women? Give me a percentage answer.\n",
    "\n",
    "**Tip:** It's `cried`, because of, you know, how books are written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['verb'] == 'cried'].pronoun.value_counts(normalize= True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How much more common is 'he' than 'she' in J.R.R. Tolkein's Fellowship of the Ring? How does that compare to Pride and Prejudice?\n",
    "\n",
    "The book is in the same directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents2 = open('data/Lord of the Rings - 01 - The Fellowship of the Ring - J. R. R. Tolkien - 1955.txt',encoding=\"utf8\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_she2 = re.findall(r\"\\bs?he\\b\", contents2, re.IGNORECASE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(he_she)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_count=0\n",
    "she_count=0\n",
    "for item in he_she2:\n",
    "    if item == 'he' or item == 'He':\n",
    "        he_count += 1\n",
    "    elif item == 'she' or item == 'She':\n",
    "        she_count += 1\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3062"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "she_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2903"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = he_count - she_count\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "she    1647\n",
       "he     1288\n",
       "Name: pronoun, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(df['pronoun'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "359"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = 1647 - 1288\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
